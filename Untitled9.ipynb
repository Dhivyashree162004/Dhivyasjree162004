{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMbs4jg3UcUQO4FV5Y4Anau",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Dhivyashree162004/Dhivyasjree162004/blob/main/Untitled9.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VHjRu8EIyxyG",
        "outputId": "cd83e2d4-688d-408b-e157-d99604c76be5"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m33.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m50.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m423.3/423.3 kB\u001b[0m \u001b[31m26.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for wikipedia (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.0/42.0 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hWikipediaBot is ready! Type 'exit' to quit.\n",
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-1-2cb3256856d9>:34: LangChainDeprecationWarning: The method `BaseRetriever.get_relevant_documents` was deprecated in langchain-core 0.1.46 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
            "  wiki_docs = wiki.get_relevant_documents(query)\n",
            "/usr/local/lib/python3.11/dist-packages/wikipedia/wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
            "\n",
            "The code that caused this warning is on line 389 of the file /usr/local/lib/python3.11/dist-packages/wikipedia/wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
            "\n",
            "  lis = BeautifulSoup(html).find_all('li')\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "WikipediaBot: **HII**, formerly known as Huntington Ingalls Industries, is the largest military shipbuilding company in the United States.  Here's a summary of key information about the company:\n",
            "\n",
            "* **Founded:** March 31, 2011 (as a spin-off from Northrop Grumman)\n",
            "* **Headquarters:** Newport News, Virginia\n",
            "* **Divisions:**\n",
            "    * Newport News Shipbuilding (Virginia): Builds and refuels nuclear-powered aircraft carriers and submarines.\n",
            "    * Ingalls Shipbuilding (Mississippi): Builds surface combatants, amphibious warships, and Coast Guard cutters.\n",
            "    * Mission Technologies: Provides professional services in areas such as IT, cybersecurity, training, and unmanned systems.\n",
            "* **Key People:**\n",
            "    * Christopher D. Kastner (President and CEO)\n",
            "    * Jennifer Boykin (President of Newport News Shipbuilding)\n",
            "    * Kari Wilkinson (President of Ingalls Shipbuilding)\n",
            "* **Notable Facts:**\n",
            "    * Sole designer, builder, and refueler of US nuclear-powered aircraft carriers.\n",
            "    * One of two shipyards capable of building nuclear-powered submarines.\n",
            "    * Sanctioned by China in 2024 for arms sales to Taiwan.\n",
            "    * Ingalls Shipbuilding is the largest manufacturing employer in Mississippi.\n",
            "\n",
            "\n",
            "Is there anything specific you'd like to know about HII?  For example, are you interested in their history, their specific products, or their financial performance?  I can provide more details if you have a particular area of interest. \n",
            "\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# STEP 1: Install Required Packages with Version Compatibility\n",
        "!pip install -q langchain langchain-community wikipedia\n",
        "!pip install -q google-generativeai langchain-google-genai\n",
        "\n",
        "# STEP 2: Import Libraries\n",
        "import os\n",
        "from langchain_community.chat_models import ChatOpenAI\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "from langchain_community.utilities import WikipediaAPIWrapper\n",
        "from langchain_community.retrievers import WikipediaRetriever\n",
        "from langchain.schema import SystemMessage, HumanMessage\n",
        "\n",
        "# STEP 3: Set your Google API Key (replace with your actual key)\n",
        "os.environ[\"GOOGLE_API_KEY\"] = \"AIzaSyCE2ip1MjmzD3t0OPUDdLZzHksAHMQDv1U\"\n",
        "\n",
        "# STEP 4: Initialize Gemini (Google Generative AI)\n",
        "def get_llm():\n",
        "    return ChatGoogleGenerativeAI(\n",
        "        model=\"gemini-1.5-pro-latest\",  # Changed to \"gemini-pro\" as \"gemini-1.5-pro-latest\" might not be available\n",
        "        google_api_key=os.getenv(\"GOOGLE_API_KEY\")\n",
        "    )\n",
        "\n",
        "llm = get_llm()\n",
        "\n",
        "# STEP 5: Set up Wikipedia Retriever\n",
        "wiki = WikipediaRetriever(\n",
        "    top_k_results=2,  # Set directly as parameter\n",
        "    lang=\"en\"\n",
        ")\n",
        "\n",
        "# STEP 6: Chatbot Function\n",
        "def wiki_chatbot(query):\n",
        "    # Get Wikipedia content\n",
        "    wiki_docs = wiki.get_relevant_documents(query)\n",
        "    context = \"\\n\\n\".join([doc.page_content for doc in wiki_docs])\n",
        "\n",
        "    # Prompt messages\n",
        "    messages = [\n",
        "        SystemMessage(content=\"You are a helpful assistant who uses Wikipedia content to answer questions.\"),\n",
        "        HumanMessage(content=f\"Here is some Wikipedia info:\\n\\n{context}\\n\\nNow answer this question: {query}\")\n",
        "    ]\n",
        "\n",
        "    # Get LLM response\n",
        "    response = llm.invoke(messages)\n",
        "    return response.content\n",
        "\n",
        "# STEP 7: Chat Loop\n",
        "print(\"WikipediaBot is ready! Type 'exit' to quit.\\n\")\n",
        "while True:\n",
        "    user_input = input(\"You: \")\n",
        "    if user_input.lower() in [\"exit\", \"quit\"]:\n",
        "        break\n",
        "    try:\n",
        "        answer = wiki_chatbot(user_input)\n",
        "        print(\"\\nWikipediaBot:\", answer, \"\\n\")\n",
        "    except Exception as e:\n",
        "        print(\"Error:\", e)"
      ]
    }
  ]
}